# Gear Building Tutorial (Part 2): BIDS Validator

In this tutorial, we will build on Gear Building Part 1: The Basics. We will learn to automatically call a subjects's input data using BIDS format, and will look at some additions required for singularity compatibility.

**Objectives:**
1. Use BIDS formatted subject level data for gear input
2. Run some computation / pipeline
3. Store results
4. Special case: Run on HPC

## Getting Started
We will start from the sucessful hello world gear. To do this, copy the project into a new directory and name it "Gear-Building-Tutorial-BIDS-Validator"

`cp -R Gear-Building-Tutorial/ Gear-Building-Tutorial-BIDS-Validator`

Next, we need to update the manifest file from our first tutorial. Here we need to update a few different key-value pairs inluding:
- `"name": "testing-bids-validator"`
- `"label": "Hello World: Advanced Using BIDS Validator"`
- `"description": "..."` *add something useful...*
- `"version": "0.1.0"`

We also need to update the location for the source docker image. Similar to the [Gear Building Part 1: The Basics](), the docker image is the container where all the code for the flywheel gear resides. The manifest file remains on the outside of the container and directs flywheel how to run the docker image. Here we will change the image to the following:
- `"image": "<docker_user>/gear-tutorial-bidsvalidator:0.1.0"`

Finally, we need to update the list of inputs and outputs we plan to use in this gear. For the purposes of this tutorial, we are not going to pass any file inputs, or file outputs. We will look at how this is done later. The inputs section will look like this:
```json
  "inputs": {
    "key": {
        "base": "api-key",
        "read-only": true
    }
  },
```
We will discuss the use of an api key later in this tutorial.

Lets put the manifest all together, your manifest file should look as follows:
```json
manifest.json
{
  "name": "testing-bids-validator",
  "label": "Hello World: Advanced Using BIDS Validator",
  "description": "Exploring gear building functionality, hello world gears are tutorials for running gears. This tutorial will use use a availible tool, BIDS validator to explore the use of BIDS formatted analysis pipelines.",
  "version": "0.1.10",
  "author": "Amy Hegarty",
  "maintainer": "Amy Hegarty <amhe4269@colorado.edu>",
  "cite": "",
  "license": "Apache-2.0",
  "url": "",
  "source": "",
  "environment": {
    "FLYWHEEL": "/flywheel/v0"
  },
  "custom": {
    "gear-builder": {
      "category": "analysis",
      "image": "amhe4269/gear-tutorial-bidsvalidator:0.1.1"
    },
    "flywheel": {
      "suite": "Flywheel Training Gears"
    }
  },
  "inputs": {
    "key": {
        "base": "api-key",
        "read-only": true
    }
  },
  "config": {
  },
  "command": "python run.py"
}
```

## BIDS Data in Flywheel Gear
Using a bids dataset in the flywheel gear can be genereated directly from the flywheel software development kit (SDK), and does **not** require naming each of your input files in the manifest file. 

### Step 1: Add necessary packages to Dockerfile
We will start from the same dockerfile from Gear Building Part 1: The Basics. A few critical peices of information, this image is build using alpine, a very light weight version of linux. Apline software can be found here. Remember that `apk` is used for package installation. 

We need to add the flywheel sdk, gear toolkit and bids python packages to interact with our run script. We will also include the bids_validator as we will use this package to check if the BIDS dataset is correctly organized.
```
RUN pip install flywheel-sdk \
                 flywheel-gear-toolkit    \
                 flywheel-bids    \
                 bids_validator   
```
Make sure this section of code is added below the `RUN` bucket where pip is installed.

### Step 2. Add Api-Key as a required input in Manifest.json
As hinted at above, we need to add a new input to the `Manifest.json`. This input is a flag for the flywheel ***api-key***, which will be generated by the person running the gear on flywheel. This helps protect the integrity of the aquisition data stored in flywheel, and used to confirm that the flywheel user who runs the gear has the appropriate privileges to interact with the dataset. For more information on the subject, check out the flywheel documentation [here](https://gitlab.com/flywheel-io/public/gears/-/tree/master/spec#api-keys).
```json
"inputs": {
    "key": {
        "base": "api-key",
        "read-only": true
    }
  },
```

### Step 3. Add Python Function Set (utils/BIDS)
Next, we need to add a set of commands that we will use to interact with flywheel dataset while running the gear. This includes two major pieces: (1) identifying where the gear was launched (i.e. which group, project, subject, session - if applicable) and (2) download the necessary data for analysis.

Here is the bare bones needed to get started using BIDS. More complicated examples will be discussed in later tutorials. 
```python
utils/bids/run_level.py
#!/usr/bin/env python3
"""Determine level at which the gear is running."""

import logging

from flywheel import ApiException

log = logging.getLogger(__name__)


def get_run_level_and_hierarchy(fw, destination_id):
    """Determine the level at which a job is running, given a destination

    Args:
        fw (gear_toolkit.GearToolkitContext.client): flywheel client
        destination_id (id): id of the destination of the gear

    Returns:
        hierarchy (dict): containing the run_level and labels for the
            run_label, group, project, subject, session, and
            acquisition.

    Note:
        This returns "no_parent" for run_level when the destination has no
        parent and returns run_level of "no_destination" if the destination
        has no "parents" attribute.  In both of these cases, if the job's
        destination.type is "acquisition" then the job is likely a utility
        gear running on an acquisition.
        This function is meant to be run by analysis gears.
    """

    try:
        destination = fw.get(destination_id)

        parent = destination.get("parent", None)
        if parent:
            run_level = destination.parent.type
        else:
            run_level = "no_parent"
        log.info("run_level = %s", run_level)

        group = destination.parents["group"]
        log.info("group = %s", group)

        if destination.parents["project"]:
            project = fw.get(destination.parents["project"])
            project_label = project.label
        else:
            project_label = "unknown project"
        log.info("project_label = %s", project_label)

        if destination.parents["subject"]:
            subject = fw.get(destination.parents["subject"])
            # subject_code = subject.code
            subject_label = subject.label
            # subject_master_code = subject.master_code
            # subject_firstname = subject.firstname
            # subject_lastname = subject.lastname
        else:
            subject_label = "unknown subject"
        log.info("subject_label = %s", subject_label)

        if destination.parents["session"]:
            session = fw.get(destination.parents["session"])
            session_label = session.label
        else:
            session_label = "unknown session"
        log.info("session_label = %s", session_label)

        if destination.parents["acquisition"]:
            acquisition = fw.get(destination.parents["acquisition"])
            acquisition_label = acquisition.label
        else:
            acquisition_label = "unknown acquisition"
        log.info("acquisition_label = %s", acquisition_label)

        if run_level == "project":
            run_label = project_label
        elif run_level == "subject":
            run_label = subject_label
        elif run_level == "session":
            run_label = session_label
        elif run_level == "acquisition":
            run_label = acquisition_label
        elif run_level == "no_parent":
            run_label = "unknown"

    except ApiException as err:
        logging.exception("Unable to get level and hierarchy")
        run_level = "no_destination"
        run_label = "unknown"
        group = None
        project_label = None
        subject_label = None
        session_label = None
        acquisition_label = None

    hierarchy = {
        "run_level": run_level,
        "run_label": run_label,
        "group": group,
        "project_label": project_label,
        "subject_label": subject_label,
        "session_label": session_label,
        "acquisition_label": acquisition_label,
    }

    return hierarchy

```



### Step 4. Update run.py, Download BIDS within Container
Next we need to add some syntax within the `run.py` script to call the above function and download the bids formated data in the gear enviornment.
```python
from utils.bids.run_level import get_run_level_and_hierarchy

#look for subject and session info...
bids_dir = Path(FLYWHEEL_BASE / "work/bids")

destination_id = gtk_context.destination["id"]
hierarchy = get_run_level_and_hierarchy(gtk_context.client, destination_id)

# download BIDS data...only download data for this session AND this subject
bids_path = gtk_context.download_project_bids(
    target_dir=bids_dir,
    src_data=False,
    folders=['anat', 'func'],
    dry_run=False,
    subjects=[hierarchy["subject_label"]],
    sessions=[hierarchy["session_label"]],
)
```

All set! You now have a function that downloads your subject-level BIDS dataset into the flywheel container. This dataset can be used at the input to any number of BIDS compliant apps / pipelines. Let's test that this step worked correctly. We will add some checkpoints in our run.py script to confirm the BIDS dataset was downloaded in the location we expect, and with the correct naming convention.

To test that the BIDS dataset was correctly downloaded, lets add the following file check after the `gtk_context.download_project_bids()` command.
```python
print(str(bids_path))
os.system('ls -l '+str(bids_path)+'/sub-*/*/*')
```

## Running In Singularity 
The next objective we will tackle, is ensuring the gear is compatible with singularity. Here we need to make sure that the bids files (and outputs) are written into a directory with write permissions. 

### Step 2.1 Add Python Function Set (utils/singularity.py)
Singularity is a container software that is most commonly used on high performance compute (HPC) enviornments. Flywheel gears are compatible with the singularity platform, ***however*** there is one big snag when working with singularity. Singularity containers are run with **non-root** privileges, meaning anything built within docker using root privileges may encounter permissions errors when run within singularity. Flywheel suggests a simple fix to combat the issue of singularity: link all files to a writable location `/tmp/`. For more information on this issue, visit the flywheel documentation [here]().

First, we will add a set of functions to our python package deck to link all flywheel directories to a `/tmp`.
```python
import logging
import os
import shutil
import tempfile
from glob import glob
from pathlib import Path

log = logging.getLogger(__name__)

# Set the typical home directory for the gear, if running in Docker
FWV0 = "/flywheel/v0"
# Set a subdirectory name for the gear directories/files that will
# be linked from FLYWHEEL to /tmp. /tmp is auto-mounted by Singularity,
# so adding another layer of organization below /tmp will allow one to
# search for Flywheel-created files/dirs to remove, zip, use, etc. easily.
gear_temp_dir = "gear-temp-dir-"


def check_for_singularity():
    """Determine if Singularity is enabled on the system and log it."""
    if "SINGULARITY_NAME" in os.environ:
#        remove_previous_runs()
        mount_gear_home_to_tmp()
        log_singularity_details()
        return True
    else:
        return False


def mount_gear_home_to_tmp():
    """
    - Singularity auto-mounts /tmp and /var/tmp.
    - The Docker run.py script is initialized after creation of the
    Singularity container.
    - Therefore, there is no opportunity to mount /flywheel/v0 data
    or structure directly to Singularity.
    The resulting necessity is to use this method to create a
    subfolder inside the automounted /tmp directory that will
    contain the files Docker is instructed to use to run the gear.
    """
    # Create temporary place to run gear
    work_dir = tempfile.mkdtemp(prefix=gear_temp_dir, dir="/tmp")
    new_FWV0 = Path(work_dir + FWV0)
    new_FWV0.mkdir(parents=True)
    
    abs_path = Path(".").resolve()
    fw_paths = list(Path(FWV0).glob("*"))

    for fw_name in fw_paths:
        if fw_name.name == "gear_environ.json":  # always use real one, not dev
            (new_FWV0 / fw_name.name).symlink_to(Path(FWV0) / fw_name.name)
        else:
            (new_FWV0 / fw_name.name).symlink_to(abs_path / fw_name.name)

    os.chdir(new_FWV0)
    
    return new_FWV0


def log_singularity_details():
    """Help debug Singularity settings, including permissions and UID."""
    log.info(f"SINGULARITY_NAME is {os.environ['SINGULARITY_NAME']}")
    log.debug(f"UID is {os.getuid()}")
    log.debug("Permissions: 4=read, 2=write, 1=exec")
    locs = glob("/tmp/*") + glob("/flywheel/v0/*") + glob("/home/bidsapp")
    for loc in locs:
        for prmsn in [os.R_OK, os.W_OK, os.X_OK]:
            log.debug(f"Permission {prmsn} for {loc}: {os.access(loc,prmsn)}")
        if ("gear_environ" in loc) and not os.access(loc, os.R_OK):
            log.error(
                "Cannot read gear_environ.json. Gear will download BIDS in the wrong spot and will not wrap up properly."
            )


def remove_previous_runs():
    """remove any previous runs (possibly left over from previous testing)"""
    previous_runs = glob(os.path.join("/tmp", gear_temp_dir + "*"))
    if previous_runs:
        log.debug("previous_runs = %s", previous_runs)
        for prev in previous_runs:
            log.debug("rm %s", prev)
            shutil.rmtree(prev)
    else:
        log.debug(f"No previous runs to worry about.")


def unlink_gear_mounts():
    """
    Clean up the shared environment, since pieces (like FreeSurfer) may have
    left remnants in /tmp/flywheel/v0.
    """
    tmp_fw_dir = os.path.join("/tmp", gear_temp_dir + "*")
    if tmp_fw_dir:
        for item in glob(tmp_fw_dir, recursive=True):
            if os.path.islink(item):
                os.unlink(item)  # don't remove anything links point to
                log.debug("unlinked {item}")
        shutil.rmtree(tmp_fw_dir)
        log.debug(f"Removed {tmp_fw_dir}")

```

### Step 2.2. Point FLYWHEEL BASE to a temporary directory
Next we need to call the functions defined above in `run.py` to set the new working directory location.
```python
#always run in a newly created "scratch" directory in /tmp/...
scratch_dir = mount_gear_home_to_tmp()
config_path = scratch_dir / 'config.json'

# Decide which env is available
use_singularity = check_for_singularity()
```

### Step 2.3. Update Dockerfile to run as non-root user
Finally, within the container build process we can set the container to build as a non-root user. We do this by specifying a `USER`. 

```
# Create Flywheel User
RUN adduser --disabled-password --gecos "Flywheel User" flywheel

USER flywheel
```

Lets test it!! You need to run the flywheel gear on your high perforamce compute (using flywheel tag: `hpc`). 

## Adding Run Command
Now we have all the building blocks set, we will add the main computation for the pipeline. In this case we will run the BIDS Validator to check the bids dataset downloaded in the flywheel container can be used for any BIDS compatible pipeline.

### Step 3.1 Add Run Command
(TO DO)... add description and example code

### Step 3.2 Store Outputs
(TO DO)... add description and example code
