# Gear Building Tutorial (Part 2): BIDS Validator

In this tutorial, we will build on Gear Building Part 1: The Basics. We will learn to automatically call a subjects's input data using BIDS format, and will look at some additions required for singularity compatibility.

**Objectives:**
1. Use BIDS formatted subject level data for gear input
2. Run some computation / pipeline
3. Store results
4. Special case: Run on HPC

## Getting Started
We will start from the sucessful hello world gear. To do this, copy the project into a new directory and name it "Gear-Building-Tutorial-BIDS-Validator"

`cp -R Gear-Building-Tutorial/ Gear-Building-Tutorial-BIDS-Validator`

Next, we need to update the manifest file from our first tutorial. Here we need to update a few different key-value pairs inluding:
- `"name": "testing-bids-validator"`
- `"label": "Hello World: Advanced Using BIDS Validator"`
- `"description": ` *add something useful...*
- `"version": "0.1.0"`

We also need to update the location for the source docker image. Similar to the [Gear Building Part 1: The Basics](), the docker image is the container where all the code for the flywheel gear resides. The manifest file remains on the outside of the container and directs flywheel how to run the docker image. Here we will change the image to the following:
- `"image": "<docker_user>/gear-tutorial-bidsvalidator:0.1.0"`

Finally, we need to update the list of inputs and outputs we plan to use in this gear. For the purposes of this tutorial, we are not going to pass any file inputs, or file outputs. We will look at how this is done later. The inputs section will look like this:
```json
  "inputs": {
    "key": {
        "base": "api-key",
        "read-only": true
    }
  },
```
We will discuss the use of an api key later in this tutorial.

Lets put the manifest all together, your manifest file should look as follows:
```json
manifest.json
{
  "name": "testing-bids-validator",
  "label": "Hello World: Advanced Using BIDS Validator",
  "description": "Exploring gear building functionality, hello world gears are tutorials for running gears. This tutorial will use use a availible tool, BIDS validator to explore the use of BIDS formatted analysis pipelines.",
  "version": "0.1.10",
  "author": "Amy Hegarty",
  "maintainer": "Amy Hegarty <amhe4269@colorado.edu>",
  "cite": "",
  "license": "Apache-2.0",
  "url": "",
  "source": "",
  "environment": {
    "FLYWHEEL": "/flywheel/v0"
  },
  "custom": {
    "gear-builder": {
      "category": "analysis",
      "image": "amhe4269/gear-tutorial-bidsvalidator:0.1.1"
    },
    "flywheel": {
      "suite": "Flywheel Training Gears"
    }
  },
  "inputs": {
    "key": {
        "base": "api-key",
        "read-only": true
    }
  },
  "config": {
  },
  "command": "python run.py"
}
```

## BIDS Data in Flywheel Gear
Using a bids dataset in the flywheel gear can be genereated directly from the flywheel software development kit (SDK), and does **not** require naming each of your input files in the manifest file. 

### Step 1: Add necessary packages to Dockerfile
We will start from the same dockerfile from Gear Building Part 1: The Basics. A few critical peices of information, this image is build using alpine, a very light weight version of linux. Apline software can be found here. Remember that `apk` is used for package installation. 

We need to add the flywheel sdk, gear toolkit and bids python packages to interact with our run script. We will also include the bids_validator as we will use this package to check if the BIDS dataset is correctly organized.
```
RUN pip install flywheel-sdk \
                 flywheel-gear-toolkit    \
                 flywheel-bids    \
                 bids_validator   
```
Make sure this section of code is added below the `RUN` bucket where pip is installed.

### Step 2. Add Api-Key as a required input in Manifest.json
As hinted at above, we need to add a new input to the `Manifest.json`. This input is a flag for the flywheel ***api-key***, which will be generated by the person running the gear on flywheel. This helps protect the integrity of the aquisition data stored in flywheel, and used to confirm that the flywheel user who runs the gear has the appropriate privileges to interact with the dataset. For more information on the subject, check out the flywheel documentation [here](https://gitlab.com/flywheel-io/public/gears/-/tree/master/spec#api-keys).
```json
"inputs": {
    "key": {
        "base": "api-key",
        "read-only": true
    }
  },
```

### Step 3. Add Python Function Set (utils/BIDS)
Next, we need to add a set of commands that we will use to interact with flywheel dataset while running the gear. This includes two major pieces: (1) identifying where the gear was launched (i.e. which group, project, subject, session - if applicable) and (2) download the necessary data for analysis.

Here is the bare bones needed to get started using BIDS. More complicated examples will be discussed in later tutorials. 
```python
utils/bids/run_level.py
#!/usr/bin/env python3
"""Determine level at which the gear is running."""

import logging

from flywheel import ApiException

log = logging.getLogger(__name__)


def get_run_level_and_hierarchy(fw, destination_id):
    """Determine the level at which a job is running, given a destination

    Args:
        fw (gear_toolkit.GearToolkitContext.client): flywheel client
        destination_id (id): id of the destination of the gear

    Returns:
        hierarchy (dict): containing the run_level and labels for the
            run_label, group, project, subject, session, and
            acquisition.

    Note:
        This returns "no_parent" for run_level when the destination has no
        parent and returns run_level of "no_destination" if the destination
        has no "parents" attribute.  In both of these cases, if the job's
        destination.type is "acquisition" then the job is likely a utility
        gear running on an acquisition.
        This function is meant to be run by analysis gears.
    """

    try:
        destination = fw.get(destination_id)

        parent = destination.get("parent", None)
        if parent:
            run_level = destination.parent.type
        else:
            run_level = "no_parent"
        log.info("run_level = %s", run_level)

        group = destination.parents["group"]
        log.info("group = %s", group)

        if destination.parents["project"]:
            project = fw.get(destination.parents["project"])
            project_label = project.label
        else:
            project_label = "unknown project"
        log.info("project_label = %s", project_label)

        if destination.parents["subject"]:
            subject = fw.get(destination.parents["subject"])
            # subject_code = subject.code
            subject_label = subject.label
            # subject_master_code = subject.master_code
            # subject_firstname = subject.firstname
            # subject_lastname = subject.lastname
        else:
            subject_label = "unknown subject"
        log.info("subject_label = %s", subject_label)

        if destination.parents["session"]:
            session = fw.get(destination.parents["session"])
            session_label = session.label
        else:
            session_label = "unknown session"
        log.info("session_label = %s", session_label)

        if destination.parents["acquisition"]:
            acquisition = fw.get(destination.parents["acquisition"])
            acquisition_label = acquisition.label
        else:
            acquisition_label = "unknown acquisition"
        log.info("acquisition_label = %s", acquisition_label)

        if run_level == "project":
            run_label = project_label
        elif run_level == "subject":
            run_label = subject_label
        elif run_level == "session":
            run_label = session_label
        elif run_level == "acquisition":
            run_label = acquisition_label
        elif run_level == "no_parent":
            run_label = "unknown"

    except ApiException as err:
        logging.exception("Unable to get level and hierarchy")
        run_level = "no_destination"
        run_label = "unknown"
        group = None
        project_label = None
        subject_label = None
        session_label = None
        acquisition_label = None

    hierarchy = {
        "run_level": run_level,
        "run_label": run_label,
        "group": group,
        "project_label": project_label,
        "subject_label": subject_label,
        "session_label": session_label,
        "acquisition_label": acquisition_label,
    }

    return hierarchy

```



### Step 4. Update run.py, Download BIDS within Container
Next we need to add some syntax within the `run.py` script to call the above function and download the bids formated data in the gear enviornment.
```python
from utils.bids.run_level import get_run_level_and_hierarchy

#look for subject and session info...
bids_dir = Path(FLYWHEEL_BASE / "work/bids")

destination_id = gtk_context.destination["id"]
hierarchy = get_run_level_and_hierarchy(gtk_context.client, destination_id)

# download BIDS data...only download data for this session AND this subject
bids_path = gtk_context.download_project_bids(
    target_dir=bids_dir,
    src_data=False,
    folders=['anat', 'func'],
    dry_run=False,
    subjects=[hierarchy["subject_label"]],
    sessions=[hierarchy["session_label"]],
)
```

All set! You now have a function that downloads your subject-level BIDS dataset into the flywheel container. This dataset can be used at the input to any number of BIDS compliant apps / pipelines. Let's test that this step worked correctly. We will add some checkpoints in our run.py script to confirm the BIDS dataset was downloaded in the location we expect, and with the correct naming convention.

To test that the BIDS dataset was correctly downloaded, lets add the following file check after the `gtk_context.download_project_bids()` command.
```python
print(str(bids_path))
os.system('ls -l '+str(bids_path)+'/sub-*/*/*')
```

## Running In Singularity 
The next objective we will tackle, is ensuring the gear is compatible with singularity. Here we need to make sure that the bids files (and outputs) are written into a directory with write permissions. 

### Step 2.1 Add Python Function Set (utils/BIDS)
(TO DO)... add description and example code

### Step 2.2. Point FLYWHEEL BASE to a temporary directory
(TO DO)... add description and example code

### Step 2.3. Update Dockerfile to run as non-root user
(TO DO)... add description and example code

Lets test it!! You need to run the flywheel gear on your high perforamce compute (using flywheel tag: `hpc`). 

## Adding Run Command
Now we have all the building blocks set, we will add the main computation for the pipeline. In this case we will run the BIDS Validator to check the bids dataset downloaded in the flywheel container can be used for any BIDS compatible pipeline.

### Step 3.1 Add Run Command
(TO DO)... add description and example code

### Step 3.2 Store Outputs
(TO DO)... add description and example code
